{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Codenet Mini Dataset Processing\n",
    "\n",
    "Steps:\n",
    "look at available problems\n",
    "Identify accecpted solutions via problem list per problem in data\n",
    "select and prune available solutions\n",
    "\n",
    "grab problem description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "from html_to_markdown import convert_to_markdown\n",
    "from alive_progress import alive_bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# codenet_dir = \"datasets/ProjectCodeNetMini\"\n",
    "codenet_dir = \"datasets/Project_CodeNet\"\n",
    "data_output_dir = \"data/human-written\"\n",
    "problem_output_dir = \"data/ai-code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_df(df: pd.DataFrame, row: list): \n",
    "  df.loc[-1] = row\n",
    "  df.index = df.index + 1  # shifting index\n",
    "  df = df.sort_index()  # sorting by index\n",
    "  return df\n",
    "\n",
    "def chunks(lst, n):\n",
    "  \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "  for i in range(0, len(lst), n):\n",
    "      yield lst[i:i + n]\n",
    "\n",
    "def get_accepted_solutions(problem: str):\n",
    "  problem_metadata = pd.read_csv(codenet_dir + \"/metadata/\" + problem + \".csv\")\n",
    "  \n",
    "  problem_c_metadata = problem_metadata[problem_metadata[\"language\"] == \"C\"]\n",
    "  problem_accepted_c = problem_c_metadata[problem_c_metadata[\"status\"] == \"Accepted\"]\n",
    "  return problem_accepted_c\n",
    "\n",
    "def get_problem_question(problem):\n",
    "  try:\n",
    "    problem_desc = open(\"datasets/ProjectCodeNetMini/problem_descriptions/\" + problem + \".html\", 'r', encoding='utf-8').read()\n",
    "    cleaned_problem_desc = convert_to_markdown(problem_desc)\n",
    "    return cleaned_problem_desc\n",
    "  except Exception as e:\n",
    "    sys.stderr.write(problem + \"\\n\")\n",
    "    return None\n",
    "\n",
    "def get_problem_data(problem: str, output_data: pd.DataFrame):\n",
    "  problem_desc = get_problem_question(problem)\n",
    "  if problem_desc == None:\n",
    "    return output_data, None\n",
    "\n",
    "  problem_accepted_c = get_accepted_solutions(problem)\n",
    "\n",
    "  # print(f\"Problem {problem} has {len(problem_accepted_c)} accepted C submissions\")\n",
    "\n",
    "  if(len(problem_accepted_c) <= 10):\n",
    "    sample_problems = problem_accepted_c\n",
    "  else:\n",
    "    sample_problems = problem_accepted_c.sample(n=10, weights=None)\n",
    "  \n",
    "  for _, row in sample_problems.iterrows():\n",
    "    submission_id = row[\"submission_id\"]\n",
    "    submission_code = open(codenet_dir + \"/data/\" + problem + \"/C/\" + str(submission_id) + \".c\", 'r', encoding='utf-8').read()\n",
    "    output_data = insert_df(output_data, [problem + \"_\" + submission_id, submission_code, 'human'])\n",
    "\n",
    "  return output_data, problem_desc\n",
    "\n",
    "def assemble_data(problems: list[str]):\n",
    "  output_data = pd.DataFrame(columns=[\"id\", \"code\", \"actual label\"])\n",
    "  problem_data = pd.DataFrame(columns=[\"question\", \"identifier\"])\n",
    "\n",
    "  for problem in problems:\n",
    "    output_data, problem_desc = get_problem_data(problem, output_data)\n",
    "    if(problem_desc == None):\n",
    "      continue\n",
    "    problem_data = insert_df(problem_data, [problem_desc, problem])\n",
    "\n",
    "  # print(output_data)\n",
    "  # print(problem_data)\n",
    "  return output_data, problem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_code = os.listdir('../bin/')\n",
    "identifier = \"dan\"\n",
    "output_name = \"Daniel-Code\"\n",
    "person_code = [code for code in all_code if code.endswith('.c')  and code.find(identifier) != -1]\n",
    "print(person_code)\n",
    "\n",
    "output_data = pd.DataFrame(columns=[\"id\", \"code\", \"actual label\"])\n",
    "for code in person_code:\n",
    "  file_code = open(\"../bin/\" + code, 'r', encoding='utf-8').read()\n",
    "  output_data = insert_df(output_data, [code, file_code, 'human'])\n",
    "\n",
    "output_data.to_pickle('../data/prepared/' + output_name + '.code.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_full = os.listdir(codenet_dir + \"/data\")\n",
    "problem_split = list(chunks(problems_full, 40))\n",
    "print(problem_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_cleaned = [x for x in tqdm(problems_full) if len(get_accepted_solutions(x)) >= 10 and get_problem_question(x) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(problems_full)} -> {len(problems_cleaned)}\")\n",
    "problem_split = list(chunks(problems_cleaned, 40))\n",
    "print(len(problem_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, problems in tqdm(enumerate(problem_split)):\n",
    "  output_data, problem_data = assemble_data(problems)\n",
    "  output_data.to_pickle(data_output_dir + f\"/codenet-full-{idx + 1}.code.pkl\")\n",
    "  problem_data.to_pickle(problem_output_dir + f\"/codenet-full-{idx + 1}.pbm.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single dataset\n",
    "problems = os.listdir(codenet_dir + \"/data\")\n",
    "output_data, problem_data = assemble_data(problems)\n",
    "\n",
    "output_data.to_pickle(data_output_dir + \"/codenet.code.pkl\")\n",
    "problem_data.to_pickle(problem_output_dir + \"/codenet-questions.pbm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = pd.read_csv(codenet_dir + \"/metadata/p00002.csv\")\n",
    "c_data = test_metadata[test_metadata[\"filename_ext\"] == \"c\"]\n",
    "accepted_c = c_data[c_data['status'] == \"Accepted\"]\n",
    "print(accepted_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
